%%%% ijcai18.tex

\typeout{IJCAI-18 Instructions for Authors}

% These are the instructions for authors for IJCAI-18.
% They are the same as the ones for IJCAI-11 with superficical wording
%   changes only.

\documentclass{article}
\pdfpagewidth=8.5in
\pdfpageheight=11in
% The file ijcai18.sty is the style file for IJCAI-18 (same as ijcai08.sty).
\usepackage{ijcai18}
\usepackage{hyperref}
% Use the postscript times font!
\usepackage{times}
\usepackage{xcolor}
\usepackage{soul}
\usepackage[utf8]{inputenc}
\usepackage[small]{caption}
\usepackage{booktabs}
\usepackage{tabu,multirow}% the following package is optional:
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{color}
%\usepackage{latexsym}

% Following comment is from ijcai97-submit.tex:
% The preparation of these files was supported by Schlumberger Palo Alto
% Research, AT\&T Bell Laboratories, and Morgan Kaufmann Publishers.
% Shirley Jowell, of Morgan Kaufmann Publishers, and Peter F.
% Patel-Schneider, of AT\&T Bell Laboratories collaborated on their
% preparation.

% These instructions can be modified and used in other conferences as long
% as credit to the authors and supporting agencies is retained, this notice
% is not changed, and further modification or reuse is not restricted.
% Neither Shirley Jowell nor Peter F. Patel-Schneider can be listed as
% contacts for providing assistance without their prior permission.

% To use for other conferences, change references to files and the
% conference appropriate and use other authors, contacts, publishers, and
% organizations.
% Also change the deadline and address for returning papers and the length and
% page charge instructions.
% Put where the files are available in the appropriate places.

\title{IJCAI--18}

% Single author syntax

\author{Di Wu, Zhennan Wang, Wenbin Zou, Xia Li, Chen Xu\\
Shenzhen University\thanks{Shenzhen Key Lab of Advanced Telecommunication and Information Processing, College of Information Engineering, Shenzhen University.}\\
{\tt\small dwu,...@szu.edu.cn}}



\begin{document}

\maketitle

\begin{abstract}
  The {\it IJCAI--18 Proceedings} will be printed from electronic
  manuscripts submitted by the authors. The electronic manuscript will
  also be included in the online version of the proceedings. This paper
  provides the style instructions.
\end{abstract}

\section{Introduction}



\subsection{A* search algorithm}

The following is an excerpt from Wikipedia \url{https://en.wikipedia.org/wiki/A*_search_algorithm}.

A* is an informed search algorithm, or a best-first search, meaning that it solves problems by searching among all possible paths to the solution (goal) for the one that incurs the smallest cost (least distance travelled, shortest time, etc.). It is an extension of Edsger Dijkstra's 1959 algorithm. A* selects the path that minimses:

\begin{equation}
f(n) = g(n) + h(n)
\end{equation}
where $n$ is the last node on the path, $g(n)$ is the cost of the path from the start node to $n$, and $h(n)$ is a heuristic that estimates the cost of the cheapest path from $n$ to the goal.
The heuristic is problem-specific. For the algorithm to find the actual shortest path, the heuristic function must be admissible, meaning that it never overestimates the actual cost to get to the nearest goal node.
Typical implementation of A* use a priority queue to perform the repeated selection of minimum (estimated) cost nodes to expand.




\section{dataset}
 \subsection{real weather update}

\section{Experiments}
\subsection{Notations}
\begin{table}[t]
\small
   \centering
        \begin{tabu}{@{}cc@{}}\toprule
        [-1pt] \tabucline[1pt]{1-2}
        Notation                       &   meaning        \\
        \hline
        xid, yid   & \\
        [-1pt] \tabucline[1pt]{1-2}
        \end{tabu}
        %\end{tabular}

    \caption{ {\small
    Results of 3D performance evaluation on mean coverage (higher is better) and center error (lower is better).
     }
          } \label{table_baseline_3d}
\end{table}

\subsection{Baselines}
\subsubsection{Straight lines}:
\subsubsection{A* 2D}
\subsubsection{A* 3D: risky scheme}
\subsubsection{A* 3D: conservative scheme}

\section{Deterministic environment}

\section{Expected Sarsa}

\section{Dyna} ~\cite{sutton1990integrated}

\section{Prioritized Sweeping} ~\cite{peng1993efficient}

\section{Eligibility traces} 
Eligibility traces in conjunction with Temporal Difference (TD) errors provide an efficient, incremental way of shifting and choosing between Monte Carlo (MC) and TD methods. Methods using eligibility traces require more computation than one-step methods, but in return they offer significantly faster learning, particularly when rewards are delayed by many steps. However, in off-line applications in which data can be generated cheaply, perhaps from an inexpensive simulation, then it often does not pay to use eligibility traces. In these cases the objective is not to get more out of a limited amount of data, but simply to process as much data as possible as quickly as possible. In these cases the speedup per datum due to traces is typically not worth their computational cost. Moreover, the tabular case is in some sense the worst cast for the computational complexity of eligibility traces~\cite{sutton2018reinforcement}.
In our problem setting, which is an off-line tabular setting, we leave out the method of eligibility traces.

\begin{table}[t]
\small
   \centering
        \begin{tabu}{@{}cccc@{}}\toprule
        [-1pt] \tabucline[1pt]{1-4}

        \multirow{2}{*}{Configuration}       &  \multicolumn{2}{c}{train (prev 12-05)}      & test (prev 12-05)   \\
                                                    &   mins                &  crash          & min     \\
            \hline
            {\small Straight Line }                 &   51318               &  31              &  69376   \\
            {\small A* 2D  }                        &   51318	            &  31              &  65656 \\
            {\small \textbf{A* 3D}(risky)}          &   \textbf{43010}      &  \textbf{21}     &  65720       \\
            {\small \textbf{A* 3D}(conservative)}   &   48874               &  29              &  \textbf{62766} \footnote{using only model 1 as forecast} \\
          [-1pt] \tabucline[1pt]{1-4}
        \end{tabu}
        %\end{tabular}

    \caption{ {\small
    Results of 3D performance evaluation on mean coverage (higher is better) and center error (lower is better).
     }
          } \label{table_baseline_3d}
\end{table}



\begin{algorithm*}[t]
\caption{3D A* Double{\color{red}(I haven't implemented double yet)} {\color{blue}Expected Sarsa} (Q-learning{\color{red}(which is better Q or ES?)}), Dyna model planning with prioritized sweeping}\label{main_algorithm}
\LinesNumbered
\SetAlgoLined
\SetAlgoNoEnd
\DontPrintSemicolon
\SetKwFunction{zeroes}{zeroes}
\KwData{\;
         $L^s = \{x^s, y^s\}$: 2D location of the starting city \;
         $L^g = \{x^g, y^g\}$: 2D location of the goal city \;
         $W_m = \{w_{x,y,t}\}$: Wind predictions of model $m \in$ $\{1, 2, \ldots, M\}$ ($M$ is the number of models) with size as  $X \times Y \times T$ \;
                                \hspace{1cm} where $X, Y$ are the grid world size and $T$ is the maximum allowed time\;
}

Generate $M$ trajectories: $J_m$ from 3D A* algorithm (conservative{\color{red}(?)}) and their corresponding policies: $\pi_m$ \;
Initialise action-value function $Q : X \times Y \times T \leftarrow 0$, $Model(s,a)$ and $PQueue$ to empty \;
Initialise starting states $S_S$ from $L^s$ as $(x^s, y^s, 0)$; goals states $S_G$ from $L_g$ as ${(x^s, y^s, t)}, t \in(1,2,\ldots T)$ and terminal states $S_T$ as ${(x, y, T)}, x \in(1,2,\ldots X), y \in(1,2,\ldots Y)$\;
$L$ is the total A* looping number{\color{red}(How to choose the number?)}, $N$ is the number of planning steps, $\theta$ is the priority threshold, $\gamma$ is the discount rate, $\alpha$ is the learning rate \;

\For{$l \leftarrow 1$ to $L$ }{
    \SetAlgoVlined
     $s_1 \leftarrow S_S$\;
     With probability $\frac{1}{m}$ , uniformly select a random wind model number $m_w$ from $\{1, 2, \ldots, M\}$ \;
     With probability $\frac{1}{m}$ , uniformly select a random policy number $m_{A*}$ from $\{1, 2, \ldots, M\}$ {\color{red}(Should $m_w, m_{A*}$ be the same?)}\;
     \For{$t \leftarrow 1$ to $T$}{
         $a_t \leftarrow \pi_{m_{A*}}$  (with probability $\epsilon$ randomly select an action, if $s_t$ is not in $\pi_{m_{A*}}$, then action is selected greedily according to $Q$) {\color{red}(How to handle expected sarsa action selectoin?)}\;
         Execute action $a_t$; observe reward $r_t$ from wind model $W_{m_w}$, and state $s_{t+1}$ \;
         $Model(s_t, a_t) \leftarrow r_t, s_{t+1}$ \; 
         $P \leftarrow |r_t + \gamma \max_a Q(s_{t+1}, a) - Q(s_t, a_t)|$ \;
         {\color{blue}$P \leftarrow |r_t + \gamma \sum_a \pi_{\epsilon}(a | s_{t+1})  Q(s_{t+1}, a) - Q(s_t, a_t)|$} \;
         if $P > \theta$, then insert $s_t, a_t$ into $PQueue$ with priority $P$ \;
         \For{$n \leftarrow 1$ to $N$ while $PQueue$ is not empty}{
             $s_n, a_n \leftarrow first(PQueue) $ \;
             $r_n, s_{n+1} \leftarrow Model(s_n, a_n)$ \;
             $Q(s_n, a_n) \leftarrow Q(s_n, a_n) + \alpha[r_n + \gamma \max_a Q(s_{n+1}, a) - Q(s_n, a_n)]  $ \;
             {\color{blue}$Q(s_n, a_n) \leftarrow Q(s_n, a_n) + \alpha[r_n + \gamma \sum_a \pi_{\epsilon}(a | s_{n+1})  Q(s_{n+1}, a) - Q(s_n, a_n)]  $ (here, $\pi_{\epsilon}$ is $\epsilon$ soft policy)} \;
             \For{all $\bar{s},\bar{a}$ predicted lead to $s_n$}{
                 $\bar{r} \leftarrow$ predicted reward for $\bar{s}, \bar{a}, s_n$ \;
                 $ P \leftarrow |\bar{r} + \gamma \max_a Q(s_n, a) - Q(\bar{s}, \bar{a})| $ \;
                 {\color{blue}$ P \leftarrow |\bar{r} + \gamma \sum_a \pi_{\epsilon}(a | s_n)  Q(s_n, a) - Q(\bar{s}, \bar{a})|$} \;
                  if $P > \theta$, then insert $\bar{s}, \bar{a}$ into $PQueue$ with priority $P$ \;
             }
         }
     if $s_{t+1}$ is in terminal states $S_T$ or goal states $S_G$, break \;
     }
}
 \;
\KwResult{\;
    Trajectory $J$ from the updated $Q$ using greedy action selection
}
\end{algorithm*}


\bibliographystyle{named}
\bibliography{ijcai18}

\end{document}

